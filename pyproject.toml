[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "dao-ai"
version = "0.0.13"
description = "DAO AI: A modular, multi-agent orchestration framework for complex AI workflows. Supports agent handoff, tool integration, and dynamic configuration via YAML."
readme = "README.md"
license = { text = "MIT" }
requires-python = ">=3.12"
authors = [
    { name = "Nate Fleming", email = "nate.fleming@databricks.com" },
    { name = "Nate Fleming", email = "nate.fleming@gmail.com" },
]
maintainers = [
    { name = "Nate Fleming", email = "nate.fleming@databricks.com" },
]
keywords = [
    "ai",
    "agents", 
    "multi-agent",
    "orchestration",
    "langgraph",
    "langchain",
    "databricks",
    "llm",
    "vector-search",
    "workflow"
]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: System :: Distributed Computing",
]
dependencies = [
    # Core framework - always required
    "langchain>=0.3.27",
    "langchain-mcp-adapters>=0.1.9",
    "langchain-text-splitters>=0.3.9",
    "langgraph>=0.6.5",
    "langgraph-checkpoint-postgres>=2.0.23",
    "langgraph-supervisor>=0.0.29",
    "langgraph-swarm>=0.0.14",
    "langmem>=0.0.29",
    "mcp>=1.9.1",
    # Core utilities - always required
    "grandalf>=0.8",
    "loguru>=0.7.3",
    "nest-asyncio>=1.6.0",
    "numpy>=1.24.0,<2.0.0",
    "pydantic>=2.11.3",
    "python-dotenv>=1.1.0",
    "pyyaml>=6.0.2",
    "rich>=14.0.0",
    "sqlparse>=0.5.3",
    "tiktoken>=0.9.0",
    # Database - required for core functionality
    "psycopg[binary,pool]>=3.2.9",
    "databricks-sdk>=0.61.0",
]

[project.scripts]
dao-ai = "dao_ai.cli:main"

[project.urls]
Homepage = "https://github.com/natefleming/dao-ai"
Documentation = "https://natefleming.github.io/dao-ai"
Repository = "https://github.com/natefleming/dao-ai"
Issues = "https://github.com/natefleming/dao-ai/issues"
Changelog = "https://github.com/natefleming/dao-ai/blob/main/CHANGELOG.md"

[project.optional-dependencies]
# Development dependencies
dev = [
    "pytest>=8.3.5",
    "ruff>=0.11.11",
    "mypy>=1.0.0",
    "pre-commit>=3.0.0",
]
docs = [
    "mkdocs>=1.5.0",
    "mkdocs-material>=9.0.0",
    "mkdocstrings[python]>=0.24.0",
]
test = [
    "pytest>=8.3.5",
    "pytest-cov>=4.0.0",
    "pytest-mock>=3.10.0",
]

# Databricks integration
databricks = [
    "databricks-agents>=1.2.0",
    "databricks-langchain>=0.4.2",
    "databricks-sdk[openai]>=0.55.0",
    "databricks-vectorsearch>=0.56",
    "databricks-connect>=15.0.0",
    "mlflow>=3.1.1",
    "unitycatalog-ai[databricks]>=0.3.0",
]

# Document processing and AI
documents = [
    "docling>=2.48.0",
    "llama-index>=0.13.3",
    "pypdf>=6.0.0",
    "openpyxl>=3.1.5",
    "torch>=2.8.0,<2.9.0",
    "scipy>=1.10.0,<1.15.0",
    "transformers>=4.40.0,<5.0.0",
]

# Complete installation with all features
all = [
    "databricks-agents>=1.2.0",
    "databricks-langchain>=0.4.2", 
    "databricks-sdk[openai]>=0.55.0",
    "databricks-vectorsearch>=0.56",
    "databricks-connect>=15.0.0",
    "docling>=2.48.0",
    "llama-index>=0.13.3",
    "mlflow>=3.1.1",
    "openpyxl>=3.1.5",
    "pypdf>=6.0.0",
    "scipy>=1.10.0,<1.15.0",
    "torch>=2.8.0,<2.9.0",
    "transformers>=4.40.0,<5.0.0",
    "unitycatalog-ai[databricks]>=0.3.0",
]

[dependency-groups]
dev = [
    "pytest>=8.3.5",
    "ruff>=0.11.11",
    "mypy>=1.0.0",
    "pre-commit>=3.0.0",
]
docs = [
    "mkdocs>=1.5.0",
    "mkdocs-material>=9.0.0", 
    "mkdocstrings[python]>=0.24.0",
]
test = [
    "pytest>=8.3.5",
    "pytest-cov>=4.0.0",
    "pytest-mock>=3.10.0",
]
databricks = [
    "databricks-agents>=1.2.0",
    "databricks-langchain>=0.4.2",
    "databricks-sdk[openai]>=0.55.0",
    "databricks-vectorsearch>=0.56",
    "databricks-connect>=15.0.0",
    "mlflow>=3.1.1",
    "unitycatalog-ai[databricks]>=0.3.0",
]
documents = [
    "docling>=2.48.0",
    "llama-index>=0.13.3",
    "pypdf>=6.0.0",
    "openpyxl>=3.1.5",
    "torch>=2.8.0,<2.9.0",
    "scipy>=1.10.0,<1.15.0",
    "transformers>=4.40.0,<5.0.0",
]
all = [
    { include-group = "databricks" },
    { include-group = "documents" },
]

[tool.hatch.build.targets.wheel]
packages = ["src/dao_ai"]
sources = ["src"]
exclude = [
    "data",
    "docs", 
    "examples",
    "functions",
    "notebooks",
    "schemas",
    "config",
    "databricks.yaml",
    "tests",
    "uv.lock",
    "Makefile",
]

[tool.hatch.build.targets.sdist]
# For source distribution, include more files that developers might need
exclude = [
    ".databricks",
    ".vscode", 
    ".pytest_cache",
    ".ruff_cache",
    ".env",
    "uv.lock",
]

[tool.ruff]
# Enable the Ruff formatter
target-version = "py312"  # Specify your Python version
line-length = 88  # Same as Black's default
indent-width = 4

# Add the formatter section
[tool.ruff.format]
quote-style = "double"  # Black uses double quotes
indent-style = "space"
skip-magic-trailing-comma = false
line-ending = "auto"

# Set directories to include/exclude
[tool.ruff.lint]
select = ["E", "F", "I"]  # You can add more linting rules here
ignore = []
fixable = ["ALL"]
unfixable = []

# Exclude files/directories
exclude = [
    ".bzr",
    ".direnv",
    ".eggs",
    ".git",
    ".git-rewrite",
    ".hg",
    ".mypy_cache",
    ".nox",
    ".pants.d",
    ".pytype",
    ".ruff_cache",
    ".svn",
    ".tox",
    ".venv",
    "__pypackages__",
    "_build",
    "buck-out",
    "build",
    "dist",
    "node_modules",
    "venv",
]
