# Example configuration for prompt optimization in dao-ai
# This demonstrates how to optimize prompts using MLflow's prompt optimization



schemas:
  main_schema: &main_schema
    catalog_name: nfleming
    schema_name: main

resources:
  llms:
    # Source model (the model you're migrating from)
    source_llm: &source_llm
      name: databricks-claude-sonnet-4-5
      temperature: 0.1
      max_tokens: 8192
    
    # Target model (the model you're migrating to - usually cheaper/faster)
    target_llm: &target_llm
      name: databricks-meta-llama-3-3-70b-instruct
      temperature: 0.1
      max_tokens: 8192

# Define the prompts to optimize
prompts:
  sentiment_classifier: &sentiment_prompt
    name: sentiment_classifier
    schema: *main_schema
    description: "Classifies text sentiment"
    default_template: |
      Classify the sentiment. Answer 'positive' or 'negative' or 'neutral'.
      Text: {{text}}

agents:
  # Agent using the target model
  sentiment_agent: &sentiment_agent
    name: sentiment_agent
    description: "Sentiment classification agent"
    model: *target_llm
    prompt: *sentiment_prompt

# Define prompt optimizations
optimizations:
  # Define training datasets (optional - can also reference existing datasets by name)
  training_datasets:
    # Example dataset with inline data
    sentiment_migration_dataset: &sentiment_migration_dataset
      # Optional: Specify schema for full catalog.schema.table name
      schema: *main_schema
      name: sentiment_migration_dataset
      data:
        - inputs:
            question: "This product is amazing!"
          expectations:
            expected_response: "positive"
        - inputs:
            question: "Terrible experience"
          expectations:
            expected_response: "negative"
        - inputs:
            question: "The service was okay"
          expectations:
            expected_response: "neutral"

  prompt_optimizations:
    # Optimize the sentiment classifier prompt for the new model
    optimize_sentiment:
      name: optimize_sentiment
      prompt: *sentiment_prompt
      agent: *sentiment_agent
      
      # Dataset reference - can be:
      # 1. String name referencing training_datasets (above)
      # 2. String name of existing dataset in MLflow
      # 3. Inline EvaluationDatasetModel with data
      dataset: *sentiment_migration_dataset
      
      # Option 3: Inline dataset (alternative to referencing training_datasets)
      # dataset:
      #   name: inline_dataset
      #   data:
      #     - inputs:
      #         question: "Example"
      #       expectations:
      #         expected_response: "positive"
      
      # Optional: Specify reflection model (defaults to agent's model)
      # Can be LLMModel reference or string model name
      reflection_model: *source_llm
      # Or use string: reflection_model: "databricks-claude-sonnet-4-5"
      
      # Optional: Optimization parameters
      num_candidates: 5  # Number of candidate prompts to generate
      max_steps: 3       # Maximum optimization steps
      
      # Optional: Specify scorer model (defaults to "databricks")
      # Can be LLMModel reference or string model name
      scorer_model: *source_llm
      # Or use string: scorer_model: "databricks-claude-sonnet-4-5"
      
      # Optional: Temperature for generation
      temperature: 0.0

# Application configuration
app:
  name: prompt_optimization_example
  log_level: DEBUG
  registered_model:
    schema: *main_schema
    name: sentiment_agent_optimized
  agents:
    - *sentiment_agent

# Example workflow for using prompt optimization:
#
# 1. Create a training dataset:
#    Option A: Define in YAML under optimizations.training_datasets
#    Option B: Create dataset programmatically and reference by name
#    Option C: Use existing dataset by name (will be looked up from MLflow)
#
# 2. Configure optimization in your YAML:
#    - Define training datasets (optional, in training_datasets)
#    - Define the prompt to optimize (in prompt_optimizations)
#    - Specify the target agent (with new model)
#    - Reference the dataset by name (string)
#    - Set optimization parameters
#
# 3. Run optimization notebook:
#    - Use notebooks/10_optimize_prompts.py
#    - This will:
#      a. Create/update datasets from training_datasets
#      b. Iterate all prompt_optimizations
#      c. Register new optimized prompt versions in MLflow
#
# 4. Evaluate and deploy:
#    - Review optimized prompts in MLflow
#    - Use notebooks/07_run_evaluation.py to evaluate
#    - Update your config to use the optimized prompt version
#    - Deploy with notebooks/05_deploy_agent.py

# Example Python code to work with datasets programmatically:
# 
# from dao_ai.config import (
#     load_config, 
#     EvaluationDatasetModel, 
#     EvaluationDatasetEntryModel,
#     EvaluationDatasetInputsModel,
#     EvaluationDatasetExpectationsModel,
#     SchemaModel
# )
# 
# # Load config
# config = load_config("config/examples/prompt_optimization.yaml")
# 
# # Access training datasets
# if config.optimizations:
#     for name, dataset in config.optimizations.training_datasets.items():
#         print(f"Dataset: {name}")
#         print(f"Full name: {dataset.full_name}")  # e.g., "catalog.schema.dataset"
#         mlflow_dataset = dataset.as_dataset()
# 
# # Create dataset programmatically with schema
# schema = SchemaModel(catalog_name="my_catalog", schema_name="my_schema")
# dataset = EvaluationDatasetModel(
#     name="my_dataset",
#     schema=schema,
#     data=[
#         EvaluationDatasetEntryModel(
#             inputs=EvaluationDatasetInputsModel(question="What is sentiment analysis?"),
#             expectations=EvaluationDatasetExpectationsModel(
#                 expected_response="Sentiment analysis is the process..."
#             )
#         ),
#         # Or use expected_facts instead of expected_response
#         EvaluationDatasetEntryModel(
#             inputs=EvaluationDatasetInputsModel(question="What are the benefits?"),
#             expectations=EvaluationDatasetExpectationsModel(
#                 expected_facts=["Improved accuracy", "Better insights", "Cost effective"]
#             )
#         )
#     ]
# )
# # This will use full_name: "my_catalog.my_schema.my_dataset"
# mlflow_dataset = dataset.as_dataset()
# 
# # Run all optimizations
# if config.optimizations:
#     results = config.optimizations.optimize()
#     for opt_name, optimized_prompt in results.items():
#         print(f"{opt_name}: {optimized_prompt.uri}")

